<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.26.2 by Michael Rose
  Copyright 2013-2024 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->

<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Research - Windfallen</title>
<meta name="description" content="Leveraging multi-agent reinforcement learning for robotic harvesting of windfallen fruit.">



<meta property="og:type" content="website">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Windfallen">
<meta property="og:title" content="Research">
<meta property="og:url" content="http://localhost:4000/research/">


  <meta property="og:description" content="Leveraging multi-agent reinforcement learning for robotic harvesting of windfallen fruit.">












<link rel="canonical" href="http://localhost:4000/research/">












<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Windfallen Feed">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
  
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single" dir="ltr">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          Windfallen
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a
                href="/home/"
                
                
              >Robotic Harvesting</a>
            </li><li class="masthead__menu-item">
              <a
                href="/motivation/"
                
                
              >Motivation</a>
            </li><li class="masthead__menu-item">
              <a
                href="/research/"
                
                
              >Research</a>
            </li><li class="masthead__menu-item">
              <a
                href="/acknowledgements/"
                
                
              >Acknowledgements</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      





<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person" class="h-card">

  

  <div class="author__content">
    <h3 class="author__name p-name" itemprop="name">
      <a class="u-url" rel="me" href="http://localhost:4000/" itemprop="url"></a>
    </h3>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer me">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Research">
    
    
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">
            <a href="http://localhost:4000/research/" itemprop="url">Research
</a>
          </h1>
          


        </header>
      

      <section class="page__content" itemprop="text">
        
        <p>Multi–agent reinforcement learning (MARL) has been an active field of research for over a decade. However, research pushing the field toward real-world use cases is less common. 
Our research provides a first look at the potential of MARL in an agricultural setting. We focus on the use case of harvesting windfallen apples and expect this technology to be easily transferable to other crops like oranges or walnuts.</p>

<p>Research in this field has largely been conducted in simple, 2D environments that minimally represent real-world circumstances. InstaDeep’s Jumanji research library, for example, offers 22 such environments.5 We provide a novel environment developed based on field measurements of real apple orchards. This environment randomly generates an orchard with real-world dimensions where agents are trained to carry out the task of collecting windfallen apples. In conducting this research, we achieve the first step toward deploying a robotic fleet to collect windfallen fruit and provide valuable insight for the research community on the viability of MARL in real world settings.</p>

<h3 id="approach">Approach</h3>

<p>A MARL implementation of this use case, fondly referred to as “Applesauce”, was adapted from the Jumanji and Mava research libraries.5, 6 Both libraries are research tools developed by InstaDeep to speed the rate of MARL research. Because training MARL algorithms requires millions of training steps at a minimum, parallelization is key to efficient research and development. Mava, Jumanji, and our “Applesauce” implementation are all built using Google’s Jax and Flax python libraries, which enable parallel computation with minimal code changes.</p>

<p><img src="/assets/images/underlying_architecture.jpg" alt="windfallen apples" style="width: 100%; margin-bottom: 10px;" /></p>

<h4 id="environment">Environment</h4>

<p>At the core of our research is a novel environment for testing assumptions for the robotic harvesting use case. To this end, our team leveraged field measurements across ten apple orchards near Santa Cruz, CA to inform realistic dimensions of orchards as well as their tree density. Applesauce’s infrastructure randomly generates orchards with different dimensions so that a variety of orchard environments are included in the training and evaluation processes.</p>

<p><img src="/assets/images/orchard_gmaps.jpg" alt="windfallen apples" style="width: 100%; margin-bottom: 10px;" /></p>

<p>In addition to a more realistic layout, we improve upon currently available environments by:</p>

<ol>
  <li>
    <p><strong>Establishing agents with a much larger action space:</strong> Agents can rotate to almost any angle, enabling more targeted movements across the orchard. This is a step beyond Jumanji’s Level-Based Foraging environment, which limits agents’ range of motion to forward, backward, left or right.</p>
  </li>
  <li>
    <p><strong>Implementing a continuous environment space:</strong> Whereas other research environments use a discrete environment space (sometimes referred to as a grid world), the Applesauce environment allows agents to navigate to any point in continuous 2D space. This results in a larger set of possible environment states and more sparse positive rewards, making this a much larger and more challenging training task.</p>
  </li>
</ol>

<h4 id="model-training">Model Training</h4>

<p>At a high level, reinforcement learning trains a model to interface with an environment. At each time step, the model receives information on the state (or observation) of the environment as well as its reward based on previous actions, and outputs a next action to take with the goal of maximizing its rewards. The Applesauce infrastructure follows this concept, using multi-agent proximal policy optimization (MAPPO) for training.</p>

<p><img src="/assets/images/applesauce_infra.jpg" alt="windfallen apples" style="width: 100%; margin-bottom: 10px;" /></p>

<p><strong>Training Architecture:</strong> The Multi-Agent Proximal Policy Optimization (MAPPO) training architecture is well suited for cooperative tasks such as ours.7 Proximal policy optimization controls the size of policy updates, increasing the likelihood that the model converges which is not always the case for MARL. MAPPO further incorporates a centralized value function for calculating the Generalized Advantage Estimation (GAE) of all agents’ actions, resulting in more collaborative behavior overall.</p>

<p><strong>Reward Function:</strong> Critical to any reinforcement learning model is a well-thought out reward function, lest your agents fool you by finding a loophole! Through qualitative observation and fine tuning, we developed a complex set of positive and negative rewards:</p>

<ul>
  <li>
    <p>Positive rewards for: picking up an apple, dropping an apple in the bin</p>
  </li>
  <li>
    <p>Negative rewards for: out of bounds, taking a step, improper attempt to pick up, improper attempt to drop, dropping an apple not in bin, no action (noop), colliding, hoarding</p>
  </li>
</ul>

<h4 id="evaluation">Evaluation</h4>

<p>We measure the performance of MARL against two different baselines. The first is an algorithmic A* baseline which directs agents to the nearest apple from the agent. The second, more interesting, is the human baseline. Would it be possible for these agents (or robots in the physical world) to outperform humans?</p>

<p>Our primary evaluation metric is the amount of apples collected per hour.. We use best practices for statistically significant evaluation based on the principles documented by Gorsane, et al.</p>

<p><img src="/assets/images/results.jpg" alt="windfallen apples" style="width: 100%; margin-bottom: 10px;" /></p>

<p>The MARL algorithm beat out the algorithmic (A*) baseline, but humans are still expected to be faster at this early stage. Despite a human’s time efficient performance, certain benefits of robotic deployment mean this result is still promising. A robot is ‘always on’ and can pick windfallen apples as soon as they fall, increasing farmers’ yield of usable windfall apples. We expect this increase in produce yield, coupled with the increasing affordability of robotic deployment, mean that these results still indicate a strong upside for farmers to deploy robots. Further, as robotic engineering progresses, it is reasonable to assume that robots may progress to carrying more than one apple at once, a feature which would close the gap between human and robotic performance.</p>

<h4 id="key-learnings--impact">Key Learnings &amp; Impact</h4>

<p>This project provided an excellent opportunity to connect experts in the field of agriculture with those in MARL research. Our guiding light has been to improve our agricultural systems through robotic deployment, and we were excited to learn how open the agricultural community is to adopting these technologies! Our initial research provided a first pass at assessing the potential of robotic deployment for windfallen apples, and can serve as a benchmark for future agriculture focused use cases within the MARL research community.</p>

<h4 id="future-work">Future Work</h4>

<p>The Windfallen team intends to publish research in 2025 after adding a few additional components to our system. Namely, we will incorporate moveable bins to reduce the travel time for picker agents and incorporate fog of war to simulate agents being dropped in a new, unmapped space. Beyond these features, future work could move toward adding a time-series component for short term memory, advancing to a 3D environment, and tuning communication methods between agents.</p>

        
      </section>

      <footer class="page__meta">
        
        


        

      </footer>

      

      

    </div>

    
  </article>

  
  
</div>

      
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
          <li><a href="https://github.com/riverliway/applesauce" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2024 <a href="http://localhost:4000">Windfallen</a>. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/jekyll-themes/minimal-mistakes/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>






  </body>
</html>
